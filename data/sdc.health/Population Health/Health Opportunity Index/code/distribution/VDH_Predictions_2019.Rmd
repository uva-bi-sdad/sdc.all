---
title: "VDH Predictions 2019"
author: "Michael Vaden"
date: "2024-04-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Libraries

```{r, echo=FALSE, include=FALSE}
#file.choose()
library(readxl)
library(tidyverse)
library(tidymodels)
library(gt)
library(gWQS)
library(car)
```

# Prep 2020 Data

### Data Processing and Imputation

```{r}
Raw_HOI_Indicators <- read_excel("/Users/michaelvaden/Downloads/HOI V3 14 Variables_For UVA.xlsx")
# use this path within repo:
# read_excel("~/git/sdc.health_dev/Access to Care (HOI)/data/distribution/HOI V3 14 Variables_For UVA.xlsx")
```


### Join Life Expectancy and Tracts

Add life expectancy and impute it

```{r}
HOI_Life_Expectancy <- read_excel("/Users/michaelvaden/Downloads/LE_Virginia.xlsx")
# use this path within repo:
# read_excel("~/git/sdc.health_dev/Access to Care (HOI)/data/distribution/LE_Virginia.xlsx")

HOI_combined = Raw_HOI_Indicators %>% left_join(HOI_Life_Expectancy %>% rename("CT2" = `Census tract`), by="CT2") %>% rename("LifeExpectancy" = "e(0)")

#sum(is.na(HOI_combined$LifeExpectancy))

knn_recipe <- recipe(LifeExpectancy ~ ., data = HOI_combined) %>%
  step_string2factor(all_nominal_predictors()) %>%
  step_impute_knn(LifeExpectancy, neighbors = round(sqrt(nrow(HOI_combined))))

HOI_recipe <- prep(knn_recipe, training = HOI_combined)
HOI_imputed <- bake(HOI_recipe, HOI_combined)

HOI_imputed$LifeExpectancy <- round(HOI_imputed$LifeExpectancy, 5)
```

```{r}
sprintf("there were %d missing values in life expectancy, but there are now %d after using knn imputation", sum(is.na(HOI_combined$LifeExpectancy)),  sum(is.na(HOI_imputed$LifeExpectancy)))
```


Scale all of the values for predicting incarceration, HOI, LEB in 2020 data

```{r}
# Function to scale numeric columns between 0 and 1
scale_numeric <- function(x) {
  if (is.numeric(x)) {
    x <- (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
  }
  return(x)
}

# scale the indicators to be between 0 and 1 to match scaled HOI data
normalized_df <- HOI_imputed %>%
  mutate(across(where(is.numeric), scale_numeric)) %>% mutate_if(is.numeric, round, digits=3)
# invert the last 8 scaled indicators to match given HOI data
normalized_df[,11:18] = 1- normalized_df[,11:18] 

names(normalized_df) = gsub("\\*", "", names(normalized_df))
# take out tract info and total population
geo_labels = normalized_df[,1:4]
# create matrix of just numeric 14 indicators
data_matrix = normalized_df[,c(5:18, 20)]
```


# Get 2019 Data

### take function from tract_conversions.R

```{r}
source("/Users/michaelvaden/Downloads/tract_conversions.R")
```

### Function to Convert to 2020

problems:
- function does not work with 2021 data
- function returns 2186 (most of the time) tracts. There are only ~1900 tracts in Virginia. The sharepoint data has 2168.
- for now, we subset to the same tracts that are in the sharepoint data

```{r}
convert_tract_to_2020 <- function(data, specified_year) {
  # filter to specified year
  year_filtered = data %>% filter(year == specified_year)

  # Filter to only include tract geographies
  year_filtered = year_filtered %>% filter(nchar(geoid) == 11)
  
  # Specify region type for function to run
  year_filtered = year_filtered %>% mutate(region_type = "tract")
  
  # Pass through the function that standardizes to 2020
  standardized_data = standardize_all(year_filtered, filter_geo = 'state')
  
  # Subset to only the new standardized data
  subset_standard = standardized_data[grepl("std$", standardized_data$measure), ]
  
  # Subset tracts to only be the ones in the original 2020 HOI data from sharepoint
  subset_tracts  = subset_standard %>% inner_join(normalized_df, by = c("geoid" = "CT2")) # 14/18 of the lost tracts were NA
  
  # return only the tract and value
  return (subset_tracts[, 1:2])
}
```


```{r}
labor_force_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/labor_participate_rate.csv"), 2019)

employment_access_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/employment_access_index.csv"), 2019)

income_inequality_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/gini_index.csv") %>% distinct(), 2019)

material_deprivation_indicator_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/material_deprivation_indicator.csv"), 2019)

education_raw_2019 = read_csv("/Users/michaelvaden/Downloads/average_years_schooling.csv") %>% mutate(geoid = as.character(geoid)) %>% filter(year == 2019)
average_years_schooling_2019 = convert_tract_to_2020(education_raw_2019[!duplicated(education_raw_2019$geoid, fromLast = TRUE),], 2019)

# for access to food we need to use 2017 data for access to food, does not exist for 2018
access_to_food_new = read_csv("/Users/michaelvaden/Downloads/food_access_percentage.csv") %>% filter(year == 2017) %>% mutate(geoid = as.character(geoid))
access_to_food_new_2017 = access_to_food_new %>% dplyr::select(geoid, value)

mobility_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/perc_moving.csv"), 2019)

population_density_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/population_density_direct.csv"), 2019)

segregation_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/segregation_indicator.csv"), 2019)

affordability_2019 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/affordability_index.csv"), 2019)

# environmental only comes from 2022 so we use that here
environment_hazard_2022 <- read_csv("/Users/michaelvaden/Downloads/environmental_hazard_index.csv")

incarceration = read_csv("/Users/michaelvaden/Downloads/incarceration_rate_per_100000.csv")

# for access to care we need to use 2017 data, but are going to drop anyway
access_care_2017 = convert_tract_to_2020(read_csv("/Users/michaelvaden/Downloads/access_care_indicator.csv") %>% mutate(geoid = as.character(geoid)), 2017)
```

Get Walkability specifically

```{r}
# walkability requires reading in from gdb file from walkability index website
library(sf)

gdb_file <- "/Users/michaelvaden/Downloads/WalkabilityIndex/Natl_WI.gdb"
gdb_data <- st_read(dsn = gdb_file)
gdb_df = st_drop_geometry(gdb_data) %>% filter(STATEFP == 51)
gdb_df <- gdb_df  %>% rename(geoid = GEOID10) %>%
  mutate(tract = substr(geoid, 1, 11))

walkability_index_weighted <- gdb_df %>%
  group_by(tract) %>%
  summarise(walkability_index = weighted.mean(NatWalkInd, TotPop))

walkability_index_weighted_for_function = walkability_index_weighted %>% rename(geoid = tract) %>% rename(value = walkability_index) %>% mutate(year = 2019) %>% mutate(measure = "walkability_index_raw") %>% mutate(moe = NA)

walkability_2021 = convert_tract_to_2020(walkability_index_weighted_for_function, 2019)
```


## Combine 2019 Predictors

```{r}
list_2019 = list(access_care_2017, average_years_schooling_2019, employment_access_2019, labor_force_2019, population_density_2019, walkability_2021, segregation_2019, income_inequality_2019, affordability_2019, environment_hazard_2022, access_to_food_new_2017, material_deprivation_indicator_2019, incarceration %>% filter(year == 2019), mobility_2019)

hoi_recreated_indicators_2019 <- Reduce(function(x, y) left_join(x, y, by = "geoid"), list_2019)
names(hoi_recreated_indicators_2019)

hoi_recreated_indicators_2019 = hoi_recreated_indicators_2019 %>% dplyr::select(-c("year.x","measure.x", "moe.x", "year.y", "measure.y", "moe.y"))

geoid_recreated = hoi_recreated_indicators_2019$geoid
hoi_recreated_matrix_2019 = hoi_recreated_indicators_2019[,2:15]

names(hoi_recreated_matrix_2019) = names(data_matrix)

hoi_recreated_matrix_2019$geoid = geoid_recreated
```


### Reorder the indicators to order of given HOI data

Reordering the indicators since the linear regression is trained on the HOI data and want to compare

```{r}
geoid_order <- match(normalized_df$CT2, hoi_recreated_matrix_2019$geoid)
#view(hoi_recreated_matrix_2017)

# Reorder the geoid column in df1 based on its order in df2
hoi_recreated_reorders_2019 <- hoi_recreated_matrix_2019[geoid_order, ]
```

### Impute the missing values

```{r}
impute_mean <- function(x) {
  if (is.numeric(x)) {
    x[is.na(x)] <- mean(x, na.rm = TRUE)
  }
  return(x)
}

hoi_recreated_imputed_2019 <- mutate_all(hoi_recreated_reorders_2019, .funs = impute_mean)

colSums(is.na(hoi_recreated_imputed_2019))
```


### Normalize predictors and reverse the last 6

```{r}
hoi_recreated_normalized_2019 <- hoi_recreated_imputed_2019 %>% dplyr::select(-c(Incarceration)) %>% mutate(across(where(is.numeric), scale_numeric)) %>% mutate_if(is.numeric, round, digits=3)

hoi_recreated_normalized_2019[,8:13] = 1 - hoi_recreated_normalized_2019[,8:13]
```


## Predict Incarceration (Proof of concept 2019)

### Predict Incarceration Train Model

Predict with 2020 data

```{r}
predict_incarceration = lm(Incarceration~., data=data_matrix %>% dplyr::select(-c(`Accees to Care`, `LifeExpectancy`)))

#summary(predict_incarceration)
```

```{r}
#inc_2017_predicted = predict(predict_incarceration, hoi_recreated_imputed_2017 %>% dplyr::select(-c(Incarceration, geoid)))
inc_2019_predicted = predict(predict_incarceration, hoi_recreated_normalized_2019 %>% dplyr::select(-c(geoid, `Accees to Care`)))

cor(inc_2019_predicted, data_matrix$Incarceration)
```


## Aggregate data to predict 2019 HOI

```{r}
indicators_2019 = hoi_recreated_normalized_2019 %>% mutate(Incarceration = inc_2019_predicted)
```


```{r}
desired_order <- c(names(indicators_2019))

HOI_results <- read_excel("/Users/michaelvaden/Downloads/HOI V3_4 Components_PCA weights.xlsx")

# joining the HOI composite index with the data frame of predictors
t = HOI_results %>% dplyr::select(CT, `Composite Index Standardized`) %>% rename(CT2 = CT)
combined = Raw_HOI_Indicators %>% full_join(t, by="CT2")


X1 = combined[,5:18]

# reorder and rename
reordered_X_columns <- c("**Accees to Care", "Education", "Employment Access", "Labor Force Participation", "Population Density", "Walkability", "**Spatial Segregation", "Income Inequality", "Affordability*", "Environmental*", "Food Access*", "Townsend*", "Mobility*", "Incarceration*")

X1 <- X1[, reordered_X_columns]

names(X1) = names(indicators_2019 %>% dplyr::select(-c(geoid)))

# attach HOI values
X1$HOI = combined$`Composite Index Standardized`
#building the model
predict_HOI_model = lm(HOI~., data=X1 %>% dplyr::select(-c(`Accees to Care`)))
#summary(predict_HOI_model)
```


## Predict HOI with 2019 data

```{r}
HOI_predicted_2019 <- predict(predict_HOI_model, indicators_2019 %>% dplyr::select(-c(`Accees to Care`))) * -1

cor(X1$HOI, HOI_predicted_2019)
```


## Predict Life Expectancy with 2019 data

```{r}

X1$LifeExpectancy = HOI_imputed$LifeExpectancy

predict_LE_model = lm(LifeExpectancy~., data=X1 %>% dplyr::select(-c(`Accees to Care`, HOI)))
#summary(predict_LE_model)
```

```{r}
LE_predicted_2019 <- predict(predict_LE_model, indicators_2019 %>% dplyr::select(-c(`Accees to Care`))) * -1

cor(X1$LifeExpectancy, LE_predicted_2019)
```

# Save The Data

```{r}
HOI_data_2019 = indicators_2019 %>% select(geoid) %>% mutate(year = 2019) %>% mutate(measure = "HOI") %>% mutate(value = HOI_predicted_2019) %>% mutate(moe = NA)

HOI_data_2019

#write.csv(HOI_data_2019, "health_opportunity_indicator_2019.csv")
```

```{r}
incarceration_data_2019 = indicators_2019 %>% select(geoid) %>% mutate(year = 2019) %>% mutate(measure = "incarceration_rate_per_100000") %>% mutate(value = inc_2019_predicted) %>% mutate(moe = NA)

incarceration_data_2019

#write.csv(incarceration_data_2019, "incarceration_rate_per_100000_2019.csv")
```

